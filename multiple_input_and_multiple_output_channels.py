# -*- coding: utf-8 -*-
"""Multiple Input and Multiple Output Channels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VoZCWUSCy2rYnG-Tpa1oy-bmjFmOuumT
"""

#Multiple Input Channels

from mxnet import np,npx
from mxnet.gluon import nn

npx.set_np()

def corr2d_multi_in(X, K):
# First, iterate through the 0th dimension (channel dimension) of `X` and
# `K`. Then, add them together
  return sum(corr2d_multi_in(x, k) for x, k in zip(X, K))

X = np.array([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = np.array([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])

corr2d_multi_in(X, K)

#Multiple Output Channels

def corr2d_multi_in_out(X, K):
# Iterate through the 0th dimension of `K`, and each time, perform
# cross-correlation operations with input `X`. All of the results are
# stacked together
  return np.stack([corr2d_multi_in(X, k) for k in K], 0)

K = np.stack((K, K + 1, K + 2), 0)
K.shape

corr2d_multi_in(X, K)

#Convolutional Layer

def corr2d_multi_in_out_1x1(X, K):
  c_i, h, w = X.shape
  c_o = K.shape[0]
  X = X.reshape((c_i, h * w))
  K = K.reshape((c_o, c_i))
# Matrix multiplication in the fully-connected layer
  Y = np.dot(K, X)
  return Y.reshape((c_o, h, w))

X = np.random.normal(0, 1, (3, 3, 3))
K = np.random.normal(0, 1, (2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in(X, K)
assert float(np.abs(Y1 - Y2).sum())

